{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "# Load the data\n",
    "store = pd.read_csv('store.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "train = pd.read_csv('train.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on the 'Store' column\n",
    "trainStore = pd.merge(train, store, on='Store')\n",
    "trainStore.to_csv('trainStore.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainStore = trainStore.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "trainStore_encoded_label = trainStore.copy()\n",
    "\n",
    "for column in trainStore_encoded_label.columns:\n",
    "    if trainStore_encoded_label[column].dtype == 'object':\n",
    "        trainStore_encoded_label[column] = label_encoder.fit_transform(trainStore_encoded_label[column])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Model Metrics:\n",
      "Mean Squared Error (MSE): 426792.36811765796\n",
      "R-squared (R2): 0.9650369559667998\n",
      "\n",
      "Gradient Boosting Model Metrics:\n",
      "Mean Squared Error (MSE): 157082.49578983596\n",
      "R-squared (R2): 0.9871317234622364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Split the dataframe into input features (X) and target variable (y)\n",
    "X = trainStore_encoded_label.drop('Sales', axis=1)\n",
    "y = trainStore_encoded_label['Sales']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create an instance of the KNN model\n",
    "knn = KNeighborsRegressor()\n",
    "\n",
    "# Fit the KNN model on the training data\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Predict the sales using the trained KNN model on the testing data\n",
    "y_pred_knn = knn.predict(X_test)\n",
    "\n",
    "# Calculate KNN model metrics\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "r2_knn = r2_score(y_test, y_pred_knn)\n",
    "\n",
    "# Define the parameter grid for Gradient Boosting\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.5],\n",
    "    'max_depth': [3, 4, 5]\n",
    "}\n",
    "\n",
    "# Create an instance of the Gradient Boosting model\n",
    "gradient_boost = GradientBoostingRegressor()\n",
    "\n",
    "# Perform Grid Search to find the best parameters\n",
    "grid_search = GridSearchCV(gradient_boost, param_grid, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best parameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Use the best parameters to create an instance of the Gradient Boosting model\n",
    "best_gradient_boost = GradientBoostingRegressor(**best_params)\n",
    "\n",
    "# Fit the Gradient Boosting model on the training data\n",
    "best_gradient_boost.fit(X_train, y_train)\n",
    "\n",
    "# Predict the sales using the trained Gradient Boosting model on the testing data\n",
    "y_pred_gb = best_gradient_boost.predict(X_test)\n",
    "\n",
    "# Calculate Gradient Boosting model metrics\n",
    "mse_gb = mean_squared_error(y_test, y_pred_gb)\n",
    "r2_gb = r2_score(y_test, y_pred_gb)\n",
    "\n",
    "# Print KNN model metrics\n",
    "print(\"KNN Model Metrics:\")\n",
    "print(\"Mean Squared Error (MSE):\", mse_knn)\n",
    "print(\"R-squared (R2):\", r2_knn)\n",
    "\n",
    "# Print Gradient Boosting model metrics\n",
    "print(\"\\nGradient Boosting Model Metrics:\")\n",
    "print(\"Mean Squared Error (MSE):\", mse_gb)\n",
    "print(\"R-squared (R2):\", r2_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9871731308771833\n",
      "Mean Squared Error (MSE): 156577.03726437106\n",
      "R-squared (R2): 0.9871731308771833\n"
     ]
    }
   ],
   "source": [
    "#apply the best params to the model and predict the sales\n",
    "best_gradient_boost = GradientBoostingRegressor(**best_params)\n",
    "best_gradient_boost.fit(X_train, y_train)\n",
    "y_pred = best_gradient_boost.predict(X_test)\n",
    "accuracy = best_gradient_boost.score(X_test, y_test)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean Squared Error (MSE):\", mse)\n",
    "print(\"R-squared (R2):\", r2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Id\nFeature names seen at fit time, yet now missing:\n- Customers\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m         testStore_encoded_label[column] \u001b[38;5;241m=\u001b[39m label_encoder\u001b[38;5;241m.\u001b[39mfit_transform(testStore_encoded_label[column])\n\u001b[0;32m      9\u001b[0m X_test \u001b[38;5;241m=\u001b[39m testStore_encoded_label\n\u001b[1;32m---> 10\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mbest_gradient_boost\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m testStore[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m y_pred\n\u001b[0;32m     12\u001b[0m testStore[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mId\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSales\u001b[39m\u001b[38;5;124m'\u001b[39m]]\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msubmission.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\basePython\\Lib\\site-packages\\sklearn\\ensemble\\_gb.py:1779\u001b[0m, in \u001b[0;36mGradientBoostingRegressor.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1764\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X):\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Predict regression target for X.\u001b[39;00m\n\u001b[0;32m   1766\u001b[0m \n\u001b[0;32m   1767\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;124;03m        The predicted values.\u001b[39;00m\n\u001b[0;32m   1778\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1779\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1780\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDTYPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mC\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcsr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[0;32m   1781\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1782\u001b[0m     \u001b[38;5;66;03m# In regression we can directly return the raw value from the trees.\u001b[39;00m\n\u001b[0;32m   1783\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_raw_predict(X)\u001b[38;5;241m.\u001b[39mravel()\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\basePython\\Lib\\site-packages\\sklearn\\base.py:579\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_validate_data\u001b[39m(\n\u001b[0;32m    509\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    510\u001b[0m     X\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_validation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    515\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params,\n\u001b[0;32m    516\u001b[0m ):\n\u001b[0;32m    517\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001b[39;00m\n\u001b[0;32m    518\u001b[0m \n\u001b[0;32m    519\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    577\u001b[0m \u001b[38;5;124;03m        validated.\u001b[39;00m\n\u001b[0;32m    578\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 579\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_feature_names\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    581\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_tags()[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires_y\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    582\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    583\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m estimator \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    584\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequires y to be passed, but the target y is None.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    585\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\rapha\\anaconda3\\envs\\basePython\\Lib\\site-packages\\sklearn\\base.py:506\u001b[0m, in \u001b[0;36mBaseEstimator._check_feature_names\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    501\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m missing_names \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m unexpected_names:\n\u001b[0;32m    502\u001b[0m     message \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    503\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFeature names must be in the same order as they were in fit.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    504\u001b[0m     )\n\u001b[1;32m--> 506\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(message)\n",
      "\u001b[1;31mValueError\u001b[0m: The feature names should match those that were passed during fit.\nFeature names unseen at fit time:\n- Id\nFeature names seen at fit time, yet now missing:\n- Customers\n"
     ]
    }
   ],
   "source": [
    "#predict the sales in the test data\n",
    "testStore = pd.merge(test, store, on='Store')\n",
    "testStore = testStore.dropna()\n",
    "testStore_encoded_label = testStore.copy()\n",
    "for column in testStore_encoded_label.columns:\n",
    "    if testStore_encoded_label[column].dtype == 'object':\n",
    "        testStore_encoded_label[column] = label_encoder.fit_transform(testStore_encoded_label[column])\n",
    "\n",
    "X_test = testStore_encoded_label\n",
    "y_pred = best_gradient_boost.predict(X_test)\n",
    "testStore['Sales'] = y_pred\n",
    "testStore[['Id', 'Sales']].to_csv('submission.csv', index=False)\n",
    "\n",
    "# Plot the feature importance\n",
    "feature_importance = best_gradient_boost.feature_importances_\n",
    "feature_names = X.columns\n",
    "sorted_idx = np.argsort(feature_importance)\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.barh(range(len(sorted_idx)), feature_importance[sorted_idx], align='center')\n",
    "plt.yticks(range(len(sorted_idx)), [feature_names[i] for i in sorted_idx])\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.title('Gradient Boosting Feature Importance')\n",
    "plt.show()\n",
    "\n",
    "# Plot the actual vs predicted sales\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.plot([0, 1], [0, 1], '--k')\n",
    "plt.xlabel('Actual Sales')\n",
    "plt.ylabel('Predicted Sales')\n",
    "plt.title('Actual vs Predicted Sales')\n",
    "plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
